{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deepr[cpu]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning\n",
    "\n",
    "This notebook builds upon the previous [pipeline example](https://criteo.github.io/deepr/getting_started/pipeline.html). The goal is to perform hyperparameter search by varying the learning rate and batch size.\n",
    "\n",
    "To launch an HP search, the steps are\n",
    "\n",
    "1. Download / retrieve some config and its macros (usually saved as MLFlow artifacts).\n",
    "2. Prepare the config by adding new macro parameters for a macro named \"params\" (for example change `\"learning_rate\": 0.1` to `\"learning_rate\": \"$params:learning_rate\"`).\n",
    "3. Define a sampler.\n",
    "4. Launch a tuning job using the prepared config, macros and sampler.\n",
    "\n",
    "First, some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"cluster_pack\").setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import deepr as dpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare config\n",
    "\n",
    "You can either manually create a config or download it from other experiments (using mlflow)\n",
    "\n",
    "To download it from mlflow you can either use bash:\n",
    "\n",
    "\n",
    "```bash\n",
    "deepr download_config_and_macros_from_mlflow --run_id=841d3f9f2ba4b69921b426a81fd --tracking_uri=$MLFLOW_TRACKING_URI\n",
    "```\n",
    "\n",
    "It will download config and macros artifact to `config.json` and `macros.json` paths from some run id\n",
    "\n",
    "Alternatively, you can download it from python:\n",
    "    \n",
    "```python\n",
    "run_id=\"841d3f9f2ba4b69921b426a81fd\"\n",
    "tracking_uri=\"https://mlflow.crto.in/\"\n",
    "\n",
    "dpr.cli.download_config_and_macros_from_mlflow(\n",
    "    run_id=run_id,\n",
    "    path_config=\"config.json\",\n",
    "    path_macros=\"macros.json\",\n",
    "    tracking_uri=tracking_uri\n",
    ")\n",
    "```\n",
    "\n",
    "To download macros you can do:\n",
    "\n",
    "```bash\n",
    "deepr add_macro --config=config.json --macros=macros.json --params=learning_rate,batch_size\n",
    "```\n",
    "\n",
    "Or with python\n",
    "\n",
    "```python\n",
    "dpr.cli.add_macro(\n",
    "    config=\"config.json\",\n",
    "    macros=\"macros.json\",\n",
    "    params=[\"learning_rate\", \"batch_size\"],\n",
    ")\n",
    "```\n",
    "\n",
    "You can then use:\n",
    "\n",
    "```python\n",
    "# Read job config and macros\n",
    "job = dpr.io.read_json(\"config.json\")\n",
    "macros = dpr.io.read_json(\"macros.json\")\n",
    "```\n",
    "\n",
    "Alternatively, define macros and configs manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"type\": \"deepr.jobs.yarn_launcher.YarnLauncher\",\n",
    "    \"job\": {\n",
    "        \"type\": \"deepr.jobs.Pipeline\",\n",
    "        \"eval\": None,\n",
    "        \"jobs\": [\n",
    "            {\n",
    "                \"type\": \"deepr.examples.multiply.jobs.build.Build\",\n",
    "                \"path_dataset\": \"viewfs://root/user/deepr/dev/example/data.tfrecord\",\n",
    "                \"num_examples\": 1000,\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"deepr.jobs.YarnTrainer\",\n",
    "                \"trainer\": {\n",
    "                    \"type\": \"deepr.jobs.Trainer\",\n",
    "                    \"path_model\": \"$paths:path_model\",  # Uses macro \"paths:path_model\"\n",
    "                    \"pred_fn\": {\"type\": \"deepr.examples.multiply.layers.model.Multiply\"},\n",
    "                    \"loss_fn\": {\"type\": \"deepr.examples.multiply.layers.loss.SquaredL2\"},\n",
    "                    \"optimizer_fn\": {\n",
    "                        \"type\": \"deepr.optimizers.TensorflowOptimizer\",\n",
    "                        \"optimizer\": \"Adam\",\n",
    "                        \"learning_rate\": \"$params:learning_rate\",  # Uses macro \"params:learning_rate\"\n",
    "                    },\n",
    "                    \"train_spec\": {\n",
    "                        \"type\": \"deepr.jobs.TrainSpec\",\n",
    "                        \"max_steps\": 1000\n",
    "                    },\n",
    "                    \"prepro_fn\": {\n",
    "                        \"type\": \"deepr.examples.multiply.prepros.default.DefaultPrepro\",  # Uses macro \"params:batch_size\"\n",
    "                        \"batch_size\": \"$params:batch_size\",\n",
    "                        \"repeat_size\": None,\n",
    "                    },\n",
    "                    \"train_input_fn\": {\n",
    "                        \"type\": \"deepr.readers.TFRecordReader\",\n",
    "                        \"path\": \"viewfs://root/user/deepr/dev/example/data.tfrecord\",\n",
    "                        \"num_parallel_reads\": 8,\n",
    "                        \"num_parallel_calls\": 8,\n",
    "                        \"shuffle\": True,\n",
    "                    },\n",
    "                    \"eval_input_fn\": {\n",
    "                        \"type\": \"deepr.readers.TFRecordReader\",\n",
    "                        \"path\": \"viewfs://root/user/deepr/dev/example/data.tfrecord\",\n",
    "                        \"num_parallel_reads\": 8,\n",
    "                        \"num_parallel_calls\": 8,\n",
    "                        \"shuffle\": True,\n",
    "                    },\n",
    "                },\n",
    "                \"config\": {\n",
    "                    \"type\": \"deepr.jobs.YarnTrainerConfig\"\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    \"config\": {\n",
    "        \"type\": \"deepr.jobs.YarnLauncherConfig\",\n",
    "        \"path_pex_prefix\": \"viewfs://root/user/deepr/dev/example/envs\",\n",
    "        \"cpu_ignored_packages\": [\"thx\"]\n",
    "    },\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We also used a dynamic macro to set the path to the model dynamically (every experiment needs to use a different model path)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "class Paths(dict):\n",
    "    \"\"\"Macro that generates new path_model based on date.\"\"\"\n",
    "\n",
    "    def __init__(self, path_model: str = None, path_dataset: str = None):\n",
    "        now = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "        if path_model is None:\n",
    "            path_model = f\"viewfs://root/user/deepr/dev/example/models/{now}\"\n",
    "        if path_dataset is None:\n",
    "            path_dataset = f\"viewfs://root/user/deepr/dev/example/data.tfrecord\"\n",
    "        super().__init__(path_model=path_model, path_dataset=path_dataset)\n",
    "\n",
    "macros = {\n",
    "    \"paths\": {\n",
    "        \"type\": \"__main__.Paths\"\n",
    "    },\n",
    "    \"params\": {\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"batch_size\": 16\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then create a short script `my_seeded_study_name.py` that looks like"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import deepr as dpr\n",
    "\n",
    "# Create sampler\n",
    "param_grid = {\n",
    "    \"learning_rate\": np.logspace(start=-5, stop=-3, num=10),\n",
    "}\n",
    "sampler = dpr.jobs.ParamsSampler(param_grid, n_iter=50, seed=42)\n",
    "\n",
    "# Create tuner and run it\n",
    "tuner = dpr.jobs.ParamsTuner(job=job, macros=macros, sampler=sampler)\n",
    "tuner.run()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Launch\n",
    "\n",
    "Now that the config is prepared, we can launch hyper parameter tuning using the `ParamsSampler` job.\n",
    "\n",
    "The only thing that it does is sampling some learning rate values and use them as macros.\n",
    "\n",
    "First, let's define a sampler for the parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\": np.logspace(start=-3, stop=-1, num=10),\n",
    "    \"batch_size\": [8, 16, 32, 64],\n",
    "}\n",
    "sampler = dpr.jobs.ParamsSampler(param_grid, n_iter=5, seed=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "and use the sampler with our config and macros to launch hyper params tuning with\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tuner = dpr.jobs.ParamsTuner(job=config, macros=macros, sampler=sampler)\n",
    "tuner.run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}